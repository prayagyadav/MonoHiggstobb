{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e959c71f-4176-4d0d-b23d-6b339e6b1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents import NanoAODSchema, NanoEventsFactory\n",
    "from coffea.analysis_tools import PackedSelection\n",
    "import awkward as ak\n",
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import hist\n",
    "import json\n",
    "import numpy as np\n",
    "from coffea.lumi_tools import LumiMask\n",
    "from coffea import processor\n",
    "from Snip_debug import *\n",
    "import crossSections\n",
    "from coffea import util\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26cf2493-894b-48ec-bc01-8618fe87cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Loadfileset():\n",
    "        def __init__(self, jsonfilename) :\n",
    "            with open(jsonfilename) as f :\n",
    "                self.handler = json.load(f)\n",
    "    \n",
    "        \n",
    "        def Show(self , verbosity=1):\n",
    "            if verbosity==1 :\n",
    "                for key, value in self.handler.items() :\n",
    "                        rich.print(key+\" : \", list(value.keys()))\n",
    "            elif verbosity==2 :\n",
    "                for key, value in self.handler.items() :\n",
    "                        rich.print(key+\" : \", list(value.keys()), \"\\n\")\n",
    "                        for subkey , subvalue in value.items() :\n",
    "                            rich.print(\"\\t\"+subkey+\" : \")\n",
    "                            for file in subvalue :\n",
    "                                rich.print(\"\\t\", file)\n",
    "            elif verbosity==3 :\n",
    "                for key, value in self.handler.items() :\n",
    "                        rich.print(key+\" : \", list(value.keys()), \"\\n\")\n",
    "                        for subkey , subvalue in value.items() :\n",
    "                            rich.print(\"\\t\"+subkey+\" : \")\n",
    "                            for subsubkey, subsubvalue in subvalue.items() :\n",
    "                                try :\n",
    "                                    for file in subvalue :\n",
    "                                        rich.print(\"\\t\", file)\n",
    "                                except:\n",
    "                                    rich.print(\"\\t\"+subsubkey+\" : \")\n",
    "        \n",
    "        def getFileset(self, mode ,superkey, key, redirector ) :\n",
    "            if redirector==\"fnal\":\n",
    "                redirector_string = \"root://cmsxrootd.fnal.gov//\"\n",
    "            elif redirector==\"infn\":\n",
    "                redirector_string = \"root://xrootd-cms.infn.it//\"\n",
    "            elif redirector==\"wisc\":\n",
    "                redirector_string = \"root://pubxrootd.hep.wisc.edu//\"\n",
    "            elif redirector==\"unl\":\n",
    "                redirector_string = \"root://xrootd-local.unl.edu:1094//\"\n",
    "            elif redirector==\"kisti\":\n",
    "                redirector_string = \"root://cms-xrdr.sdfarm.kr:1094//xrd//\"\n",
    "            raw_fileset = self.handler[mode][superkey][key] \n",
    "            requested_fileset = {superkey : [redirector_string+filename for filename in raw_fileset]}\n",
    "            return requested_fileset\n",
    "        \n",
    "        def getraw(self):\n",
    "            #load the raw dictionary\n",
    "            full_fileset = self.handler\n",
    "            return full_fileset\n",
    "def getDataset(keymap, load=True, dict = None, files=None, begin=0, end=0, mode = \"sequential\"):\n",
    "        #Warning : Never use 'files' with 'begin' and 'end'\n",
    "        fileset = Loadfileset(\"newfileset.json\")\n",
    "        fileset_dict = fileset.getraw()\n",
    "        MCmaps = [\n",
    "            \"MET_Run2018\",\n",
    "            \"ZJets_NuNu\",\n",
    "            \"TTToSemiLeptonic\",\n",
    "            \"TTTo2L2Nu\",\n",
    "    \t\"TTToHadronic\",\n",
    "            \"WJets_LNu\",\n",
    "            \"DYJets_LL\",\n",
    "            \"VV\",\n",
    "            \"QCD\",\n",
    "            \"ST\"\n",
    "            ]\n",
    "    \n",
    "        \n",
    "        runnerfileset = buildFileset(fileset_dict[keymap],\"commonfs\")\n",
    "        flat_list={}\n",
    "        flat_list[keymap] = []\n",
    "    \n",
    "        if mode == \"sequential\":\n",
    "            if end - begin < 0:\n",
    "                print(\"Invalid begin and end values.\\nFalling back to full dataset...\")\n",
    "                outputfileset = runnerfileset\n",
    "            else:\n",
    "                # for key in runnerfileset.keys() :\n",
    "                #     flat_list[keymap] += runnerfileset[key]\n",
    "                #indexer\n",
    "                index={}\n",
    "                i = 1\n",
    "                for key in runnerfileset.keys() :\n",
    "                    index[key] = []\n",
    "                    for file in runnerfileset[key] :\n",
    "                        index[key].append(i)\n",
    "                        i += 1\n",
    "    \n",
    "                accept = np.arange(begin,end+1,1)\n",
    "                print(accept)\n",
    "                temp = {}\n",
    "                for key in runnerfileset.keys() :\n",
    "                    temp[key] = []\n",
    "                    for i in range(len(runnerfileset[key])) :\n",
    "                        if index[key][i] in accept :\n",
    "                            temp[key].append(runnerfileset[key][i])\n",
    "                #outputfileset = {keymap : flat_list[keymap][(begin - 1) :end]}\n",
    "                #outputfileset = {keymap : temp}\n",
    "                outputfileset = temp\n",
    "        elif mode == \"divide\" :\n",
    "            if files == None:\n",
    "                print(\"Invalid number of files.\\nFalling back to full dataset...\")\n",
    "                outputfileset = runnerfileset\n",
    "            else:\n",
    "                # Divide the share of files from all the 8 categories of ZJets_NuNu\n",
    "                file_number = 0\n",
    "                while file_number < files :\n",
    "                    for key in runnerfileset.keys():\n",
    "                        if file_number >= files :\n",
    "                            break\n",
    "                        flat_list[keymap] += [runnerfileset[key][0]]\n",
    "                        runnerfileset[key] = runnerfileset[key][1:]\n",
    "                        file_number += 1\n",
    "                outputfileset = {keymap : flat_list[keymap]}\n",
    "        else:\n",
    "            print(\"Invalid mode of operation\", mode)\n",
    "            raise KeyError\n",
    "        \n",
    "        print(\"Running \", np.array([len(value) for value in outputfileset.values()]).sum(), \" files...\")\n",
    "        return outputfileset\n",
    "def buildFileset(dict , redirector):\n",
    "        '''\n",
    "        To return a run-able dict with the appropriate redirector.\n",
    "        Please input a dictionary which is only singly-nested\n",
    "        '''\n",
    "        redirectors = {\n",
    "            \"fnal\": \"root://cmsxrootd.fnal.gov//\",\n",
    "            \"infn\": \"root://xrootd-cms.infn.it//\",\n",
    "            \"wisc\": \"root://pubxrootd.hep.wisc.edu//\",\n",
    "            \"unl\":  \"root://xrootd-local.unl.edu:1094/\",\n",
    "            \"kisti\": \"root://cms-xrdr.sdfarm.kr:1094//xrd/\",\n",
    "            \"hdfs\": \"/hdfs\",\n",
    "            \"commonfs\": \"/commonfs\"\n",
    "    \n",
    "        }\n",
    "    \n",
    "        if (redirector==\"fnal\") | (redirector==1) :\n",
    "            redirector_string = redirectors[\"fnal\"]\n",
    "        elif (redirector==\"infn\") | (redirector==2) :\n",
    "            redirector_string = redirectors[\"infn\"]\n",
    "        elif (redirector==\"wisc\") | (redirector==3):\n",
    "            redirector_string = redirectors[\"wisc\"]\n",
    "        elif (redirector==\"unl\") | (redirector==4):\n",
    "            redirector_string = redirectors[\"unl\"]\n",
    "        elif (redirector==\"kisti\") | (redirector==5):\n",
    "            redirector_string = redirectors[\"kisti\"]\n",
    "        elif (redirector==\"hdfs\") | (redirector==6):\n",
    "            redirector_string = redirectors[\"hdfs\"]\n",
    "        elif (redirector==\"commonfs\") | (redirector==7):\n",
    "            redirector_string = redirectors[\"commonfs\"]\n",
    "    \n",
    "        temp = dict \n",
    "        output = {}\n",
    "        for key in temp.keys() :\n",
    "            try :\n",
    "                g = temp[key]\n",
    "                if isinstance(g,list):\n",
    "                    templist = []\n",
    "                    for filename in g :\n",
    "                        filename = filename[filename.find(\"/store/\") :]\n",
    "                        templist.append(redirector_string+filename)\n",
    "                    output[key] = templist\n",
    "            except :\n",
    "                raise KeyError\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b4729be-6c64-4160-9e40-1bfbb9356104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lumiobject():\n",
    "    path = \"Cert_314472-325175_13TeV_Legacy2018_Collisions18_JSON.txt\" \n",
    "    return LumiMask(path)\n",
    "\n",
    "lumimaskobject = get_lumiobject()\n",
    "\n",
    "def lumi(events,cutflow,path=\"\",lumiobject=None):\n",
    "    #Selecting use-able events\n",
    "    if lumiobject==None :\n",
    "        #path_of_file = path+\"Cert_314472-325175_13TeV_Legacy2018_Collisions18_JSON.json\"\n",
    "        path_of_file = path+\"golden.json\"\n",
    "        lumimask = LumiMask(path_of_file)\n",
    "    else :\n",
    "        lumimask = lumiobject\n",
    "    events = events[lumimask(events.run, events.luminosityBlock)]\n",
    "    cutflow[\"lumimask\"] = len(events)\n",
    "    return events , cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c615132b-44af-4b8d-bd8f-da12394b6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin the processor definition\n",
    "class Top_mu(processor.ProcessorABC):\n",
    "    \"\"\"\n",
    "    Flow of Data:\n",
    "\n",
    "    INPUT EVENTS\n",
    "        |\n",
    "        |-------------------------------------------\n",
    "        |                                           |\n",
    "        |                                           |\n",
    "        v                                           v\n",
    "        if MET_Run2018                        else if MC\n",
    "        |                                           |\n",
    "        |                                           |\n",
    "        |                                           |\n",
    "        v                                           |\n",
    "    MET TRIGGER                                     |\n",
    "        |                                           |\n",
    "        |                                           |\n",
    "        |                                           |\n",
    "        v                                           |\n",
    "    MET FILTERS                                     |\n",
    "        |                                           |\n",
    "        |<------------------------------------------\n",
    "        |                                           \n",
    "        v\n",
    "    MET CUT\n",
    "        |\n",
    "        |\n",
    "        |\n",
    "        v\n",
    "    EVENT SELECTION AND OBJECT SELECTION\n",
    "        |\n",
    "        |\n",
    "        |\n",
    "        v\n",
    "    Make MET pt eta phi, DIJET mass etc plots - all of them plots\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self,category,helper_objects = [] ):\n",
    "        # Initialize the cutflow dictionary\n",
    "        if len(helper_objects) > 0 :\n",
    "            self.lumiobject = helper_objects[0] \n",
    "        self.category = category\n",
    "        self.cutflow = {}\n",
    "        self.run_set = set({})\n",
    "\n",
    "    def process(self, events):\n",
    "        # process everything according to their recoil window\n",
    "        def process_by_recoil_window(self,events,recoil_window):\n",
    "            dataset = events.metadata[\"dataset\"]\n",
    "            self.mode = dataset\n",
    "            self.recoil_window , self.mass_nbin = recoil_window \n",
    "            cutflow = {}\n",
    "            cutflow[\"Total events\"] = len(events) #Total Number of events\n",
    "\n",
    "            #Preparing histogram objects\n",
    "            #MET\n",
    "            met_pt_min = 0\n",
    "            met_pt_max = 500\n",
    "            met_pt_nbins = 25\n",
    "            met_pt_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(met_pt_nbins,met_pt_min,met_pt_max).\n",
    "                Double()\n",
    "            )\n",
    "            met_phi_min = -3.14\n",
    "            met_phi_max = 3.14\n",
    "            met_phi_nbins = 6\n",
    "            met_phi_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(met_phi_nbins,met_phi_min,met_phi_max).\n",
    "                Double()\n",
    "            )\n",
    "            #Leading ak4bjets\n",
    "            leadingjets_pt_min = 0\n",
    "            leadingjets_pt_max = 500\n",
    "            leadingjets_pt_nbins = 25\n",
    "            leadingjets_pt_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(leadingjets_pt_nbins,leadingjets_pt_min,leadingjets_pt_max).\n",
    "                Double()\n",
    "            )\n",
    "            leadingjets_eta_min = -2.5\n",
    "            leadingjets_eta_max = 2.5\n",
    "            leadingjets_eta_nbins = 5\n",
    "            leadingjets_eta_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(leadingjets_eta_nbins,leadingjets_eta_min,leadingjets_eta_max).\n",
    "                Double()\n",
    "            )\n",
    "            leadingjets_phi_min = -3.14\n",
    "            leadingjets_phi_max = 3.14\n",
    "            leadingjets_phi_nbins = 6\n",
    "            leadingjets_phi_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(leadingjets_phi_nbins,leadingjets_phi_min,leadingjets_phi_max).\n",
    "                Double()\n",
    "            )\n",
    "            leadingjets_mass_min = 0\n",
    "            leadingjets_mass_max = 500\n",
    "            leadingjets_mass_nbins = 25\n",
    "            leadingjets_mass_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(leadingjets_mass_nbins,leadingjets_mass_min,leadingjets_mass_max).\n",
    "                Double()\n",
    "            )\n",
    "            #Subleading ak4 bjets\n",
    "            subleadingjets_pt_min = 0\n",
    "            subleadingjets_pt_max = 500\n",
    "            subleadingjets_pt_nbins = 25\n",
    "            subleadingjets_pt_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(subleadingjets_pt_nbins,subleadingjets_pt_min,subleadingjets_pt_max).\n",
    "                Double()\n",
    "            )\n",
    "            subleadingjets_eta_min = -2.5\n",
    "            subleadingjets_eta_max = 2.5\n",
    "            subleadingjets_eta_nbins = 5\n",
    "            subleadingjets_eta_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(subleadingjets_eta_nbins,subleadingjets_eta_min,subleadingjets_eta_max).\n",
    "                Double()\n",
    "            )\n",
    "            subleadingjets_phi_min = -3.14\n",
    "            subleadingjets_phi_max = 3.14\n",
    "            subleadingjets_phi_nbins = 6\n",
    "            subleadingjets_phi_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(subleadingjets_phi_nbins,subleadingjets_phi_min,subleadingjets_phi_max).\n",
    "                Double()\n",
    "            )\n",
    "            subleadingjets_mass_min = 0\n",
    "            subleadingjets_mass_max = 500\n",
    "            subleadingjets_mass_nbins = self.mass_nbin\n",
    "            subleadingjets_mass_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(subleadingjets_mass_nbins,subleadingjets_mass_min,subleadingjets_mass_max).\n",
    "                Double()\n",
    "            )\n",
    "            #ak4bjet-ak4bjet dijets \n",
    "            dijets_pt_min = 0\n",
    "            dijets_pt_max = 500\n",
    "            dijets_pt_nbins = 25\n",
    "            dijets_pt_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(dijets_pt_nbins,dijets_pt_min,dijets_pt_max).\n",
    "                Double()\n",
    "                )\n",
    "            dijets_eta_min = -2.5\n",
    "            dijets_eta_max = 2.5\n",
    "            dijets_eta_nbins = 5\n",
    "            dijets_eta_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(dijets_eta_nbins,dijets_eta_min,dijets_eta_max).\n",
    "                Double()\n",
    "                )\n",
    "            dijets_phi_min = -3.14\n",
    "            dijets_phi_max = 3.14\n",
    "            dijets_phi_nbins = 6\n",
    "            dijets_phi_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(dijets_phi_nbins,dijets_phi_min,dijets_phi_max).\n",
    "                Double()\n",
    "                )\n",
    "            dijets_mass_min = 100\n",
    "            dijets_mass_max = 150\n",
    "            dijets_mass_nbins = self.mass_nbin\n",
    "            dijets_mass_hist = (\n",
    "                hist.\n",
    "                Hist.\n",
    "                new.\n",
    "                Reg(dijets_mass_nbins,dijets_mass_min,dijets_mass_max).\n",
    "                Double()\n",
    "                )\n",
    "\n",
    "            if (self.mode).startswith(\"MET\") :\n",
    "\n",
    "                #choosing certified good events\n",
    "                should_lumi = False\n",
    "                if should_lumi :\n",
    "                    events, cutflow = lumi(events, cutflow, lumiobject=self.lumiobject)\n",
    "\n",
    "                #Saving the event run\n",
    "                for run in set(events.run):\n",
    "                    self.run_set.add(run)\n",
    "\n",
    "                #MET_Trigger\n",
    "                events, cutflow = met_trigger(events,cutflow,era=2018)\n",
    "\n",
    "                #MET_Filters\n",
    "                events, cutflow = met_filter(events,cutflow)\n",
    "            \n",
    "\n",
    "            #vetoes\n",
    "            events, cutflow = no_electrons(events,cutflow)\n",
    "            if (self.mode).startswith(\"MonoHTobb_ZpBaryonic\"):\n",
    "                events, cutflow = no_taus(events,cutflow, version=7)\n",
    "            else :\n",
    "                events, cutflow = no_taus(events,cutflow, version=9)\n",
    "            events, cutflow = no_photons(events,cutflow)\n",
    "\n",
    "            #HEM veto\n",
    "            events,cutflow = HEM_veto_bril(events,cutflow)\n",
    "\n",
    "            #Object selections\n",
    "                \n",
    "            #Exactly one tight muon\n",
    "            events, single_muons, cutflow = tight_muons(events,cutflow)\n",
    "\n",
    "            #MET_selection\n",
    "            events, cutflow = met_selection(events,cutflow,GeV=50.0)\n",
    "\n",
    "            dummy_dict = {}\n",
    "            dummy_events, single_muons, dummy_dict = tight_muons(events,dummy_dict) # I just want to get tight muons back, so I use the same function with some dummy variables\n",
    "\n",
    "            #Hadronic Recoil\n",
    "            #There is at least one muon(tight) in each event at this point\n",
    "            events.Recoil = events.MET.pt + ak.flatten(single_muons.pt)\n",
    "            # if self.category == \"boosted\" :\n",
    "            #     recoil = 250.0\n",
    "            # elif self.category == \"resolved\" :\n",
    "            #     recoil = 200.0\n",
    "            Recoil = get_recoil(events,single_muons)\n",
    "            windowcut = (Recoil > self.recoil_window[0]) & (Recoil < self.recoil_window[1])\n",
    "            events = events[windowcut]\n",
    "            cutflow[\"Recoil\"] = len(events)\n",
    "\n",
    "            #Do the calculations\n",
    "            wp = get_wp(Era=2018,wp=\"medium\")\n",
    "            is_bjet = events.Jet.btagDeepFlavB > wp\n",
    "            bjets = events.Jet[is_bjet]\n",
    "            \n",
    "            at_least_two_such_jets = ak.num(bjets, axis=1) >= 2\n",
    "            bjets = bjets[at_least_two_such_jets]\n",
    "            \n",
    "            leading_bjets = bjets[:,0]\n",
    "            leading_jet_pt_at_least_50 = leading_bjets.pt > 50\n",
    "            bjets = bjets[leading_jet_pt_at_least_50 ]\n",
    "            \n",
    "            subleading_bjets = bjets[:,1]\n",
    "            subleading_jet_pt_at_least_30 = subleading_bjets.pt > 30\n",
    "            bjets = bjets[subleading_jet_pt_at_least_30]\n",
    "            \n",
    "            dijets = bjets[:,0]+bjets[:,1]\n",
    "\n",
    "            dijets_pt_selection = dijets.pt > 100\n",
    "            dijets = dijets[dijets_pt_selection]\n",
    "            \n",
    "            dijets_mass_window = (dijets.mass < 150) & (dijets.mass > 70)\n",
    "            dijets = dijets[dijets_mass_window]\n",
    "            \n",
    "            #Reobtain the leading and subleading jets after the dijet cuts\n",
    "            leadingjets = bjets[:,0]\n",
    "            leadingjets = leadingjets[dijets_pt_selection]\n",
    "            leadingjets = leadingjets[dijets_mass_window]\n",
    "\n",
    "            subleadingjets = bjets[:,1]\n",
    "            subleadingjets = subleadingjets[dijets_pt_selection]\n",
    "            subleadingjets = subleadingjets[dijets_mass_window]\n",
    "\n",
    "            #Updating the cutflow for all the above processes\n",
    "            events = events[at_least_two_such_jets]\n",
    "            #cutflow[\"dijet events\"] = len(events)\n",
    "            \n",
    "            events = events[leading_jet_pt_at_least_50]\n",
    "            cutflow[\"leading jet pt > 50\"] = len(events)\n",
    "            \n",
    "            events = events[subleading_jet_pt_at_least_30]\n",
    "            cutflow[\"subleading jet pt > 30\"] = len(events)\n",
    "\n",
    "            events = events[dijets_pt_selection]\n",
    "            cutflow[\"pt(bb) > 100\"] = len(events)\n",
    "            \n",
    "            events = events[dijets_mass_window]\n",
    "            cutflow[\"70 < M_bb < 150\"] = len(events)\n",
    "\n",
    "            one_normal_additional_jet = ak.num(events.Jet) >= 3\n",
    "            events = events[one_normal_additional_jet]\n",
    "            pt_greater_than30 = events.Jet.pt[:,2] > 30\n",
    "            acceptable_eta = abs(events.Jet.eta[:,2] ) < 2.5\n",
    "            events = events[pt_greater_than30 & acceptable_eta]\n",
    "            cutflow[\"At least one normal additional jet\"] = len(events)\n",
    "\n",
    "            #Fill the histogram\n",
    "            #MET\n",
    "            met_pt_hist.fill(events.MET.pt)\n",
    "            met_phi_hist.fill(events.MET.phi)\n",
    "            #Leading jets\n",
    "            leadingjets_pt_hist.fill(leadingjets.pt)\n",
    "            leadingjets_eta_hist.fill(leadingjets.eta)\n",
    "            leadingjets_phi_hist.fill(leadingjets.phi)\n",
    "            leadingjets_mass_hist.fill(leadingjets.mass)\n",
    "            #Subleading jets\n",
    "            subleadingjets_pt_hist.fill(subleadingjets.pt)\n",
    "            subleadingjets_eta_hist.fill(subleadingjets.eta)\n",
    "            subleadingjets_phi_hist.fill(subleadingjets.phi)\n",
    "            subleadingjets_mass_hist.fill(subleadingjets.mass)\n",
    "            #ak4bjet-ak4bjet dijets\n",
    "            dijets_pt_hist.fill(dijets.pt)\n",
    "            dijets_eta_hist.fill(dijets.eta)\n",
    "            dijets_phi_hist.fill(dijets.phi)\n",
    "            dijets_mass_hist.fill(dijets.mass)\n",
    "        \n",
    "\n",
    "            #Prepare the output\n",
    "            key_list = [\n",
    "            \"MET_Run2018\",\n",
    "            \"ZJets_NuNu\",\n",
    "            \"TTToSemiLeptonic\",\n",
    "            \"TTTo2L2Nu\",\n",
    "            \"TTToHadronic\",\n",
    "            \"WJets_LNu\",\n",
    "            \"DYJets_LL\",\n",
    "            \"VV\",\n",
    "            \"QCD\",\n",
    "            \"ST\"\n",
    "            ]\n",
    "            if self.mode.startswith(\"MET_Run2018\") :\n",
    "                self.key = key_list[0]\n",
    "            elif \"Jets_NuNu\" in self.mode :\n",
    "                self.key = key_list[1]\n",
    "            elif self.mode.startswith(\"TTToSemiLeptonic\"):\n",
    "                self.key = key_list[2]\n",
    "            elif self.mode.startswith(\"TTTo2L2Nu\"):\n",
    "                self.key = key_list[3]\n",
    "            elif self.mode.startswith(\"TTToHadronic\"):\n",
    "                self.key = key_list[4]\n",
    "            elif self.mode.startswith(\"WJets_LNu\"):\n",
    "                self.key = key_list[5]\n",
    "            elif self.mode.startswith(\"DYJets_LL\"):\n",
    "                self.key = key_list[6]\n",
    "            elif ( self.mode.startswith(\"WW\") | self.mode.startswith(\"WZ\") | self.mode.startswith(\"ZZ\") ) :\n",
    "                self.key = key_list[7]\n",
    "            elif self.mode.startswith(\"QCD\"):\n",
    "                self.key = key_list[8]\n",
    "            elif self.mode.startswith(\"ST\"):\n",
    "                self.key = key_list[9]\n",
    "            else :\n",
    "                print(\"Unidentified dataset \", self.mode)\n",
    "                raise KeyError\n",
    "        \n",
    "\n",
    "            output_by_recoil_window = {\n",
    "                self.key : {\n",
    "                    self.mode : {\n",
    "                        \"Cutflow\": cutflow ,\n",
    "                        \"Histograms\": {\n",
    "                            \"met_pt_hist\" : met_pt_hist ,\n",
    "                            \"met_phi_hist\" : met_phi_hist ,\n",
    "                            \"leadingjets_pt_hist\" : leadingjets_pt_hist ,\n",
    "                            \"leadingjets_eta_hist\" : leadingjets_eta_hist ,\n",
    "                            \"leadingjets_phi_hist\" : leadingjets_phi_hist ,\n",
    "                            \"leadingjets_mass_hist\" : leadingjets_mass_hist ,\n",
    "                            \"subleadingjets_pt_hist\" : subleadingjets_pt_hist ,\n",
    "                            \"subleadingjets_eta_hist\" : subleadingjets_eta_hist ,\n",
    "                            \"subleadingjets_phi_hist\" : subleadingjets_phi_hist ,\n",
    "                            \"subleadingjets_mass_hist\" : subleadingjets_mass_hist ,\n",
    "                            \"dijets_pt\" : dijets_pt_hist ,\n",
    "                            \"dijets_eta\" : dijets_eta_hist ,\n",
    "                            \"dijets_phi\" : dijets_phi_hist ,\n",
    "                            \"dijets_mass\" : dijets_mass_hist ,\n",
    "                            },\n",
    "                        \"RunSet\":self.run_set\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            return output_by_recoil_window\n",
    "        \n",
    "        ##########################################################################\n",
    "        #Implementing the different regions\n",
    "        recoils = {\n",
    "            1: ([200,250],18),\n",
    "            2: ([250,290],11),\n",
    "            3: ([290,360],8),\n",
    "            4: ([360,420],4),\n",
    "            5: ([420,1000],3)\n",
    "        }\n",
    "        output = {}\n",
    "        output[\"Recoil:200-250\"] = process_by_recoil_window(self,events,recoils[1])\n",
    "        output[\"Recoil:250-290\"] = process_by_recoil_window(self,events,recoils[2])\n",
    "        output[\"Recoil:290-360\"] = process_by_recoil_window(self,events,recoils[3])\n",
    "        output[\"Recoil:360-420\"] = process_by_recoil_window(self,events,recoils[4])\n",
    "        output[\"Recoil:420-1000\"] = process_by_recoil_window(self,events,recoils[5])\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08a086b7-e508-4044-86fa-1a425593d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adder(raw_dict , onlydata = False):\n",
    "    \"\"\"\n",
    "    Adds(accumulates) the dictionaries from subcategories using cross section in case of MCs or raw in case of data \n",
    "    \"\"\"\n",
    "    if onlydata == False:\n",
    "        raw_dict = xsec_reweight(raw_dict) #Return the same dict with cross section reweighting applied to MCs\n",
    "    output_dict = {}\n",
    "    keys = list(raw_dict.keys())\n",
    "    for key in keys :\n",
    "        subkeys = list(raw_dict[key].keys())\n",
    "        temp = []\n",
    "        for subkey in subkeys :\n",
    "            temp.append(raw_dict[key][subkey])\n",
    "        output_dict[key] = processor.accumulate(temp)\n",
    "    return output_dict\n",
    "\n",
    "def xsec_reweight(input_dict):\n",
    "    \"\"\"\n",
    "    Returns the same histogram with cross section reweighting applied to every MC histogram object and cutflow dictionary\n",
    "    \"\"\"\n",
    "    lumi = crossSections.lumis[2018]\n",
    "    #print(\"Integrated Luminosity(pb): \", lumi)\n",
    "\n",
    "    #load cross sections\n",
    "\n",
    "    ZJets_NuNu_xsec = {\n",
    "        \"Z1Jets_NuNu_ZpT_50To150_18\": crossSections.crossSections[\"Z1Jets_NuNu_ZpT_50To150_18\"],\n",
    "        \"Z1Jets_NuNu_ZpT_150To250_18\": crossSections.crossSections[\"Z1Jets_NuNu_ZpT_150To250_18\"],\n",
    "        \"Z1Jets_NuNu_ZpT_250To400_18\": crossSections.crossSections[\"Z1Jets_NuNu_ZpT_250To400_18\"],\n",
    "        \"Z1Jets_NuNu_ZpT_400Toinf_18\": crossSections.crossSections[\"Z1Jets_NuNu_ZpT_400Toinf_18\"],\n",
    "        \"Z2Jets_NuNu_ZpT_50To150_18\": crossSections.crossSections[\"Z2Jets_NuNu_ZpT_50To150_18\"],\n",
    "        \"Z2Jets_NuNu_ZpT_150To250_18\": crossSections.crossSections[\"Z2Jets_NuNu_ZpT_150To250_18\"],\n",
    "        \"Z2Jets_NuNu_ZpT_250To400_18\": crossSections.crossSections[\"Z2Jets_NuNu_ZpT_250To400_18\"],\n",
    "        \"Z2Jets_NuNu_ZpT_400Toinf_18\": crossSections.crossSections[\"Z2Jets_NuNu_ZpT_400Toinf_18\"]\n",
    "    }\n",
    "\n",
    "    TTToSemiLeptonic_xsec = {\n",
    "        \"TTToSemiLeptonic_18\":crossSections.crossSections[\"TTToSemiLeptonic_18\"]\n",
    "    }\n",
    "    \n",
    "    TTTo2L2Nu_xsec = {\n",
    "        \"TTTo2L2Nu_18\": crossSections.crossSections[\"TTTo2L2Nu_18\"]\n",
    "    }\n",
    "    \n",
    "    TTToHadronic_xsec = {\n",
    "        \"TTToHadronic_18\": crossSections.crossSections[\"TTToHadronic_18\"]\n",
    "    }\n",
    "\n",
    "    WJets_LNu_xsec = {\n",
    "        \"WJets_LNu_WPt_100To250_18\": crossSections.crossSections[\"WJets_LNu_WPt_100To250_18\"],\n",
    "        \"WJets_LNu_WPt_250To400_18\": crossSections.crossSections[\"WJets_LNu_WPt_250To400_18\"],\n",
    "        \"WJets_LNu_WPt_400To600_18\": crossSections.crossSections[\"WJets_LNu_WPt_400To600_18\"],\n",
    "        \"WJets_LNu_WPt_600Toinf_18\": crossSections.crossSections[\"WJets_LNu_WPt_600Toinf_18\"],\n",
    "    }\n",
    "\n",
    "    DYJets_LL_xsec = {\n",
    "        \"DYJets_LL_Pt_0To50_18\": crossSections.crossSections[\"DYJets_LL_Pt_0To50_18\"],\n",
    "        \"DYJets_LL_Pt_50To100_18\": crossSections.crossSections[\"DYJets_LL_Pt_50To100_18\"],\n",
    "        \"DYJets_LL_Pt_100To250_18\": crossSections.crossSections[\"DYJets_LL_Pt_100To250_18\"],\n",
    "        \"DYJets_LL_Pt_250To400_18\": crossSections.crossSections[\"DYJets_LL_Pt_250To400_18\"],\n",
    "        \"DYJets_LL_Pt_400To650_18\": crossSections.crossSections[\"DYJets_LL_Pt_400To650_18\"],\n",
    "        \"DYJets_LL_Pt_650Toinf_18\": crossSections.crossSections[\"DYJets_LL_Pt_650Toinf_18\"],\n",
    "    }\n",
    "\n",
    "    VV_xsec = {\n",
    "        \"WZ_1L1Nu2Q_18\": crossSections.crossSections[\"WZ_1L1Nu2Q_18\"],\n",
    "        \"WZ_2L2Q_18\": crossSections.crossSections[\"WZ_2L2Q_18\"],\n",
    "        #\"WZ_2Q2Nu_18\": crossSections.crossSections[\"WZ_2Q2Nu_18\"],\n",
    "        \"WZ_3L1Nu_18\" : crossSections.crossSections[\"WZ_3L1Nu_18\"],\n",
    "        \"ZZ_2L2Nu_18\": crossSections.crossSections[\"ZZ_2L2Nu_18\"],\n",
    "        \"ZZ_2L2Q_18\": crossSections.crossSections[\"ZZ_2L2Q_18\"],\n",
    "        \"ZZ_2Q2Nu_18\": crossSections.crossSections[\"ZZ_2Q2Nu_18\"],\n",
    "        \"ZZ_4L_18\": crossSections.crossSections[\"ZZ_4L_18\"],\n",
    "        \"WW_2L2Nu_18\": crossSections.crossSections[\"WW_2L2Nu_18\"],\n",
    "        \"WW_1L1Nu2Q_18\": crossSections.crossSections[\"WW_1L1Nu2Q_18\"],\n",
    "    }\n",
    "\n",
    "    QCD_xsec = {\n",
    "        #\"QCD_HT100To200_18\": crossSections.crossSections[\"QCD_HT100To200_18\"],\n",
    "        \"QCD_HT200To300_18\": crossSections.crossSections[\"QCD_HT200To300_18\"],\n",
    "        \"QCD_HT300To500_18\": crossSections.crossSections[\"QCD_HT300To500_18\"],\n",
    "        \"QCD_HT500To700_18\": crossSections.crossSections[\"QCD_HT500To700_18\"],\n",
    "        \"QCD_HT700To1000_18\": crossSections.crossSections[\"QCD_HT700To1000_18\"],\n",
    "        \"QCD_HT1000To1500_18\": crossSections.crossSections[\"QCD_HT1000To1500_18\"],\n",
    "        \"QCD_HT1500To2000_18\": crossSections.crossSections[\"QCD_HT1500To2000_18\"],\n",
    "        \"QCD_HT2000Toinf_18\": crossSections.crossSections[\"QCD_HT2000Toinf_18\"],\n",
    "    }\n",
    "\n",
    "    ST_xsec = {\n",
    "        \"ST_tchannel_top_18\": crossSections.crossSections[\"ST_tchannel_top_18\"],\n",
    "        \"ST_tchannel_antitop_18\": crossSections.crossSections[\"ST_tchannel_antitop_18\"],\n",
    "        \"ST_tW_top_18\": crossSections.crossSections[\"ST_tW_top_18\"],\n",
    "        \"ST_tW_antitop_18\": crossSections.crossSections[\"ST_tW_antitop_18\"]\n",
    "    }\n",
    "\n",
    "    # #compute weight_factor for ZJets_NuNu \n",
    "    # N_i = {}\n",
    "    # ZJets_NuNu_weight_factor = {}\n",
    "    # for subkey in ZJets_NuNu_xsec.keys() :\n",
    "    #     N_i[subkey] = input_dict[\"ZJets_NuNu\"][subkey][\"Cutflow\"][\"Total events\"]\n",
    "    #     ZJets_NuNu_weight_factor[subkey] = ( lumi * ZJets_NuNu_xsec[subkey] )/N_i[subkey]\n",
    "\n",
    "    #compute weight_factor for TTToSemiLeptonic\n",
    "    N_i = {}\n",
    "    TTToSemiLeptonic_weight_factor = {}\n",
    "    for subkey in TTToSemiLeptonic_xsec.keys() :\n",
    "        N_i[subkey] = input_dict[\"TTToSemiLeptonic\"][subkey][\"Cutflow\"][\"Total events\"]\n",
    "        TTToSemiLeptonic_weight_factor[subkey] = ( lumi * TTToSemiLeptonic_xsec[subkey] )/N_i[subkey]\n",
    "\n",
    "    # #compute weight_factor for TTTo2L2Nu\n",
    "    # N_i = {}\n",
    "    # TTTo2L2Nu_weight_factor = {}\n",
    "    # for subkey in TTTo2L2Nu_xsec.keys() :\n",
    "    #     N_i[subkey] = input_dict[\"TTTo2L2Nu\"][subkey][\"Cutflow\"][\"Total events\"]\n",
    "    #     TTTo2L2Nu_weight_factor[subkey] = ( lumi * TTTo2L2Nu_xsec[subkey] )/N_i[subkey]\n",
    "\n",
    "    # #compute weight_factor for TTToHadronic\n",
    "    # N_i = {}\n",
    "    # TTToHadronic_weight_factor = {}\n",
    "    # for subkey in TTToHadronic_xsec.keys() :\n",
    "    #     N_i[subkey] = input_dict[\"TTToHadronic\"][subkey][\"Cutflow\"][\"Total events\"]\n",
    "    #     TTToHadronic_weight_factor[subkey] = ( lumi * TTToHadronic_xsec[subkey] )/N_i[subkey]\n",
    "\n",
    "    # #compute weight_factor for WJets_LNu\n",
    "    # N_i = {}\n",
    "    # WJets_LNu_weight_factor = {}\n",
    "    # for subkey in WJets_LNu_xsec.keys() :\n",
    "    #     N_i[subkey] = input_dict[\"WJets_LNu\"][subkey][\"Cutflow\"][\"Total events\"]\n",
    "    #     WJets_LNu_weight_factor[subkey] = ( lumi * WJets_LNu_xsec[subkey] )/N_i[subkey]\n",
    "\n",
    "    # #compute weight_factor for DYJets_LL\n",
    "    # N_i = {}\n",
    "    # DYJets_LL_weight_factor = {}\n",
    "    # for subkey in DYJets_LL_xsec.keys() :\n",
    "    #     N_i[subkey] = input_dict[\"DYJets_LL\"][subkey][\"Cutflow\"][\"Total events\"]\n",
    "    #     DYJets_LL_weight_factor[subkey] = ( lumi * DYJets_LL_xsec[subkey] )/N_i[subkey]\n",
    "\n",
    "    # #compute weight_factor for VV\n",
    "    # N_i = {}\n",
    "    # VV_weight_factor = {}\n",
    "    # for subkey in VV_xsec.keys() :\n",
    "    #     N_i[subkey] = input_dict[\"VV\"][subkey][\"Cutflow\"][\"Total events\"]\n",
    "    #     VV_weight_factor[subkey] = ( lumi * VV_xsec[subkey] )/N_i[subkey]\n",
    "\n",
    "    # #compute weight_factor for QCD\n",
    "    # N_i = {}\n",
    "    # QCD_weight_factor = {}\n",
    "    # for subkey in QCD_xsec.keys() :\n",
    "    #     N_i[subkey] = input_dict[\"QCD\"][subkey][\"Cutflow\"][\"Total events\"]\n",
    "    #     QCD_weight_factor[subkey] = ( lumi * QCD_xsec[subkey] )/N_i[subkey]\n",
    "\n",
    "    # #compute weight_factor for ST\n",
    "    # N_i = {}\n",
    "    # ST_weight_factor = {}\n",
    "    # for subkey in ST_xsec.keys() :\n",
    "    #     N_i[subkey] = input_dict[\"ST\"][subkey][\"Cutflow\"][\"Total events\"]\n",
    "    #     ST_weight_factor[subkey] = ( lumi * ST_xsec[subkey] )/N_i[subkey]\n",
    "\n",
    "    #individually apply cross section\n",
    "    def hist_xsec(MC_dict, key_weight_factor):\n",
    "        keys = list(MC_dict.keys())\n",
    "        \n",
    "        for key in keys:\n",
    "            #Reweight the all the cutflow events\n",
    "            cutflow_keys = list(MC_dict[key][\"Cutflow\"].keys())\n",
    "            for cutflow_key in cutflow_keys :\n",
    "                MC_dict[key][\"Cutflow\"][cutflow_key] *= key_weight_factor[key]\n",
    "                \n",
    "            # Reweight all the histograms\n",
    "            properties = list(MC_dict[key][\"Histograms\"].keys())\n",
    "            for property in properties:\n",
    "                MC_dict[key][\"Histograms\"][property] *= key_weight_factor[key]\n",
    "            #key_hists[key] *= key_weight_factor[key] #legacy\n",
    "        return MC_dict\n",
    "\n",
    "    \n",
    "    # input_dict[\"ZJets_NuNu\"] = hist_xsec(input_dict[\"ZJets_NuNu\"] , ZJets_NuNu_weight_factor)\n",
    "    input_dict[\"TTToSemiLeptonic\"] = hist_xsec(input_dict[\"TTToSemiLeptonic\"], TTToSemiLeptonic_weight_factor)\n",
    "    # input_dict[\"TTTo2L2Nu\"] = hist_xsec(input_dict[\"TTTo2L2Nu\"], TTTo2L2Nu_weight_factor)\n",
    "    # input_dict[\"TTToHadronic\"] = hist_xsec(input_dict[\"TTToHadronic\"], TTToHadronic_weight_factor)\n",
    "    # input_dict[\"WJets_LNu\"] = hist_xsec(input_dict[\"WJets_LNu\"], WJets_LNu_weight_factor)\n",
    "    # input_dict[\"DYJets_LL\"] = hist_xsec(input_dict[\"DYJets_LL\"], DYJets_LL_weight_factor)\n",
    "    # input_dict[\"VV\"] = hist_xsec(input_dict[\"VV\"], VV_weight_factor)\n",
    "    # input_dict[\"QCD\"] = hist_xsec(input_dict[\"QCD\"], QCD_weight_factor)\n",
    "    # input_dict[\"ST\"] = hist_xsec(input_dict[\"ST\"], ST_weight_factor)\n",
    "\n",
    "    return input_dict\n",
    "def simpleoverallcutflow(master_dict,dataset=\"MET_Run2018\"):\n",
    "    temp = []\n",
    "    nrecoil = 0\n",
    "    for key in master_dict:\n",
    "        nrecoil += 1\n",
    "        added = adder(master_dict[key] , onlydata=False)\n",
    "        cat_dict = added[dataset][\"Cutflow\"]\n",
    "        temp.append(cat_dict)\n",
    "    output_dict = processor.accumulate(temp)\n",
    "    #repeated_keys = [\"Total events\",\"MET trigger\",\"MET filters\",\"MET > 50.0 GeV\",\"no electrons\",\"no photons\",\"no taus\",\"HEM veto\",\"one_tight_muon\"]\n",
    "    #repeated_keys = [\"Total events\",\"MET trigger\",\"MET filters\",\"MET > 50.0 GeV\",\"no electrons\",\"no photons\",\"no taus\",\"one_tight_muon\"]\n",
    "    #repeated_keys = [\"Total events\",\"MET trigger\",\"MET filters\",\"MET > 50.0 GeV\",\"no photons\",\"no taus\",\"one_tight_muon\"]\n",
    "    repeated_keys = [\"Total events\",\"MET > 50.0 GeV\",\"no electrons\",\"no photons\",\"no taus\",\"HEM veto\",\"one_tight_muon\"]\n",
    "    for key in repeated_keys :\n",
    "        output_dict[key] = output_dict[key] / nrecoil\n",
    "    #convert values in scientific notation\n",
    "    output_dict = {key : \"{:e}\".format(value) for key,value in output_dict.items()}\n",
    "    return output_dict\n",
    "def show(dict):\n",
    "    for key in dict.keys() :\n",
    "        print(key , \" : \", dict[key] , \" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "649adfc2-d098-4821-bd5e-63bc7d6ae34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-07 22:54:38,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-k0c06fcm', purging\n",
      "2024-02-07 22:54:38,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-rbo4p8w7', purging\n",
      "2024-02-07 22:54:38,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-n850j2nf', purging\n",
      "2024-02-07 22:54:38,533 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-x9nz_lbv', purging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduler at  tcp://127.0.0.1:38399\n",
      "[1]\n",
      "Running  1  files...\n",
      "[########################################] | 100% Completed | 41.9s\u001b[2K\u001b[2K\r"
     ]
    }
   ],
   "source": [
    "run_at = \"dask\"\n",
    "begin_at = 1\n",
    "end_at = 1\n",
    "nworkers = 4\n",
    "chunk_size = 500000\n",
    "k=\"TTToSemiLeptonic\"\n",
    "def zip_files(list_of_files):\n",
    "        os.makedirs(\"temporary_folder\")\n",
    "        for file in list_of_files :\n",
    "            shutil.copy(file,\"temporary_folder\")\n",
    "        archive_name = \"helper_files\"\n",
    "        shutil.make_archive(archive_name,\"zip\",\"temporary_folder\")\n",
    "        shutil.rmtree(\"temporary_folder\")\n",
    "        return archive_name+\".zip\"\n",
    "#For futures execution\n",
    "if run_at == \"futures\" :\n",
    "    files = getDataset(keymap=k,load=True, mode=\"sequential\", begin=begin_at, end=end_at)\n",
    "    print(files)\n",
    "    futures_run = processor.Runner(\n",
    "        executor = processor.FuturesExecutor(workers=nworkers),\n",
    "        schema=NanoAODSchema,\n",
    "        chunksize=chunk_size ,\n",
    "        xrootdtimeout=120\n",
    "    )\n",
    "    Output = futures_run(\n",
    "        files,\n",
    "        \"Events\",\n",
    "        processor_instance=Top_mu(category=\"resolved\",helper_objects=[lumimaskobject])\n",
    "    )\n",
    "\n",
    "#For dask execution\n",
    "elif run_at == \"dask\" :\n",
    "    from dask.distributed import Client , LocalCluster\n",
    "    cluster = LocalCluster()\n",
    "    client = Client(cluster)\n",
    "    print(\"scheduler at \", client.scheduler.address)\n",
    "    cluster.scale(nworkers)\n",
    "\n",
    "    client.upload_file(zip_files(\n",
    "        [\n",
    "            \"Cert_314472-325175_13TeV_Legacy2018_Collisions18_JSON.txt\",\n",
    "            \"Snip_debug.py\"\n",
    "            ]\n",
    "        )\n",
    "        )\n",
    "    with open(\"newfileset.json\") as f: #load the fileset\n",
    "        filedict = json.load(f)\n",
    "    files = getDataset(keymap=k,load=True, mode=\"sequential\", begin=begin_at, end=end_at)\n",
    "    dask_run = processor.Runner(\n",
    "        executor = processor.DaskExecutor(client=client),\n",
    "        schema=NanoAODSchema,\n",
    "        chunksize= chunk_size\n",
    "    )\n",
    "    Output = dask_run(\n",
    "        files,\n",
    "        \"Events\",\n",
    "        processor_instance=Top_mu(category=\"resolved\",helper_objects=[lumimaskobject])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac8bb81-26a6-40fe-bb60-4edab9315b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the output to :  CR_resolved_Top_TTToSemiLeptonic_from_1_to_1.coffea\n",
      "File CR_resolved_Top_TTToSemiLeptonic_from_1_to_1.coffea saved.\n"
     ]
    }
   ],
   "source": [
    "output_file = f\"CR_resolved_Top_{k}_from_{begin_at}_to_{end_at}.coffea\"\n",
    "print(\"Saving the output to : \" , output_file)\n",
    "util.save(output= Output, filename=\"coffea_files/\"+output_file)\n",
    "print(f\"File {output_file} saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa9e5b7-5e81-44b2-8eec-2f479f919306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total events': 1294000, 'no electrons': 957845, 'no taus': 874189, 'no photons': 831214, 'HEM veto': 746942, 'one_tight_muon': 216485, 'MET > 50.0 GeV': 127405, 'Recoil': 9859, 'leading jet pt > 50': 4681, 'subleading jet pt > 30': 3578, 'pt(bb) > 100': 2036, '70 < M_bb < 150': 672, 'At least one normal additional jet': 642}\n",
      "{'Total events': 1294000, 'no electrons': 957845, 'no taus': 874189, 'no photons': 831214, 'HEM veto': 746942, 'one_tight_muon': 216485, 'MET > 50.0 GeV': 127405, 'Recoil': 3586, 'leading jet pt > 50': 1701, 'subleading jet pt > 30': 1294, 'pt(bb) > 100': 790, '70 < M_bb < 150': 210, 'At least one normal additional jet': 203}\n",
      "{'Total events': 1294000, 'no electrons': 957845, 'no taus': 874189, 'no photons': 831214, 'HEM veto': 746942, 'one_tight_muon': 216485, 'MET > 50.0 GeV': 127405, 'Recoil': 2617, 'leading jet pt > 50': 1306, 'subleading jet pt > 30': 1011, 'pt(bb) > 100': 705, '70 < M_bb < 150': 156, 'At least one normal additional jet': 150}\n",
      "{'Total events': 1294000, 'no electrons': 957845, 'no taus': 874189, 'no photons': 831214, 'HEM veto': 746942, 'one_tight_muon': 216485, 'MET > 50.0 GeV': 127405, 'Recoil': 812, 'leading jet pt > 50': 413, 'subleading jet pt > 30': 333, 'pt(bb) > 100': 231, '70 < M_bb < 150': 47, 'At least one normal additional jet': 46}\n",
      "{'Total events': 1294000, 'no electrons': 957845, 'no taus': 874189, 'no photons': 831214, 'HEM veto': 746942, 'one_tight_muon': 216485, 'MET > 50.0 GeV': 127405, 'Recoil': 572, 'leading jet pt > 50': 318, 'subleading jet pt > 30': 267, 'pt(bb) > 100': 211, '70 < M_bb < 150': 34, 'At least one normal additional jet': 34}\n"
     ]
    }
   ],
   "source": [
    "for key in Output.keys():\n",
    "    print(Output[key]['TTToSemiLeptonic']['TTToSemiLeptonic_18']['Cutflow'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47076d4d-fc92-48e5-b6db-7a51cae23bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events  :  2.151012e+07  \n",
      "\n",
      "no electrons  :  1.592223e+07  \n",
      "\n",
      "no taus  :  1.453162e+07  \n",
      "\n",
      "no photons  :  1.381725e+07  \n",
      "\n",
      "HEM veto  :  1.241639e+07  \n",
      "\n",
      "one_tight_muon  :  3.598624e+06  \n",
      "\n",
      "MET > 50.0 GeV  :  2.117849e+06  \n",
      "\n",
      "Recoil  :  2.900043e+05  \n",
      "\n",
      "leading jet pt > 50  :  1.399488e+05  \n",
      "\n",
      "subleading jet pt > 30  :  1.077667e+05  \n",
      "\n",
      "pt(bb) > 100  :  6.604306e+04  \n",
      "\n",
      "70 < M_bb < 150  :  1.860110e+04  \n",
      "\n",
      "At least one normal additional jet  :  1.786969e+04  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "show(simpleoverallcutflow(Output, dataset=\"TTToSemiLeptonic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1ae78-8ddf-4b89-9635-1febeb027dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
